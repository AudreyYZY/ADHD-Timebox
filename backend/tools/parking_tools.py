"""Shared parking lot service for focus/orchestration agents."""

import datetime
import json
import os
import threading
import uuid
from concurrent.futures import ThreadPoolExecutor
from enum import Enum
from typing import Any, Dict, List, Optional

try:
    # Preferred package name (avoids runtime warning in duckduckgo_search)
    from ddgs import DDGS  # type: ignore
except ImportError:
    from duckduckgo_search import DDGS  # type: ignore


class TaskStatus(str, Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"


class TaskType(str, Enum):
    SEARCH = "search"
    MEMO = "memo"
    TODO = "todo"


class ParkingService:
    """Core parking service that stores thoughts and runs optional background search."""

    def __init__(self, brain_dir: Optional[str] = None):
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.brain_dir = brain_dir or os.path.join(base_dir, "adhd_brain")
        self.parking_dir = os.path.join(self.brain_dir, "thought_parking")
        os.makedirs(self.parking_dir, exist_ok=True)

        self._current_file = os.path.join(self.parking_dir, "current_parking.json")
        self._executor = ThreadPoolExecutor(max_workers=2)
        self._session_id: Optional[str] = None
        self._lock = threading.RLock()

    # â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def dispatch_task(
        self,
        content: str,
        task_type: str = TaskType.SEARCH.value,
        source: str = "unknown",
        run_async: bool = True,
    ) -> str:
        """
        Primary entry: stash a thought or query, optionally processed in background.
        """
        normalized_type = (task_type or TaskType.SEARCH.value).lower()
        task_id = str(uuid.uuid4())[:8]
        now = datetime.datetime.now()

        task = {
            "id": task_id,
            "content": content,
            "type": normalized_type,
            "source": source,
            "status": TaskStatus.PENDING.value,
            "created_at": now.strftime("%Y-%m-%d %H:%M:%S"),
            "session_id": self._session_id,
            "result": None,
            "error": None,
        }

        self._append_task(task)
        self._log_to_daily(
            f"[{now.strftime('%H:%M:%S')}] ðŸ“¥ æ”¶åˆ°: {content} (from {source})"
        )

        if run_async and normalized_type == TaskType.SEARCH.value:
            # Fire-and-forget search so it never blocks focus flow.
            self._executor.submit(self._process_task_background, task_id)

        preview = content[:30]
        suffix = "..." if len(content) > 30 else ""
        return f"ðŸ“¥ å·²è®°å½•ï¼šã€Œ{preview}{suffix}ã€"

    def get_session_summary(self, session_id: Optional[str] = None) -> str:
        """
        Retrieve summary for the current or specified session.
        """
        target_session = session_id or self._session_id

        # å¦‚æžœ session_id ä¸ºç©ºï¼Œå±•ç¤ºæ‰€æœ‰æœ€è¿‘ sessionï¼ˆå½“å‰ç®€å•å®žçŽ°ä»…å±•ç¤ºå…¨éƒ¨ï¼‰
        if not target_session:
            return "ðŸ“­ æœ¬æ¬¡ä¸“æ³¨æœŸé—´æ²¡æœ‰æš‚å­˜çš„å¿µå¤´ã€‚"

        tasks = self._load_tasks()
        session_tasks = [
            t
            for t in tasks
            if t.get("session_id") == target_session or target_session is None
        ]

        if not session_tasks:
            return "ðŸ“­ æœ¬æ¬¡ä¸“æ³¨æœŸé—´æ²¡æœ‰æš‚å­˜çš„å¿µå¤´ã€‚"

        lines = ["ðŸ“‹ **ä¸“æ³¨æœŸé—´æš‚å­˜çš„å¿µå¤´å¤„ç†æŠ¥å‘Šï¼š**", ""]
        for task in session_tasks:
            status = task.get("status", TaskStatus.PENDING.value)
            content = task.get("content", "")[:50]
            result = task.get("result")

            if status == TaskStatus.COMPLETED.value and result:
                tail = "..." if len(result) > 200 else ""
                lines.append(f"âœ… ã€Œ{content}ã€")
                lines.append(f"   â†’ {result[:200]}{tail}")
            elif status == TaskStatus.PENDING.value:
                lines.append(f"â³ ã€Œ{content}ã€ - ä»åœ¨å¤„ç†ä¸­")
            elif status == TaskStatus.FAILED.value:
                lines.append(f"âŒ ã€Œ{content}ã€ - å¤„ç†å¤±è´¥")
            else:
                lines.append(f"ðŸ“ ã€Œ{content}ã€ - å·²è®°å½•")
            lines.append("")

        return "\n".join(lines).rstrip()

    def list_pending_tasks(self) -> str:
        """List all pending tasks for quick inspection."""
        tasks = self._load_tasks()
        pending = [t for t in tasks if t.get("status") == TaskStatus.PENDING.value]

        if not pending:
            return "ðŸ“­ å½“å‰æ²¡æœ‰å¾…å¤„ç†çš„æš‚å­˜å¿µå¤´ã€‚"

        lines = [f"ðŸ“‹ å¾…å¤„ç†ä»»åŠ¡ ({len(pending)} ä¸ª)ï¼š"]
        for task in pending:
            content = task.get("content", "")[:40]
            lines.append(f"  - {content} [{task.get('type', TaskType.MEMO.value)}]")
        return "\n".join(lines)

    def start_session(self) -> str:
        """Mark the beginning of a focus session."""
        self._session_id = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        return self._session_id

    def end_session(self) -> str:
        """End active session and return a formatted summary."""
        if not self._session_id:
            return "ðŸ“­ æœ¬æ¬¡ä¸“æ³¨æœŸé—´æ²¡æœ‰æš‚å­˜çš„å¿µå¤´ã€‚"
        summary = self.get_session_summary()
        self._session_id = None
        return summary

    # â”€â”€ Internal helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _load_tasks(self) -> List[Dict[str, Any]]:
        with self._lock:
            if not os.path.exists(self._current_file):
                return []
            try:
                with open(self._current_file, "r", encoding="utf-8") as f:
                    data = json.load(f)
                return data if isinstance(data, list) else []
            except Exception:
                return []

    def _save_tasks(self, tasks: List[Dict[str, Any]]):
        with self._lock:
            with open(self._current_file, "w", encoding="utf-8") as f:
                json.dump(tasks, f, ensure_ascii=False, indent=2)

    def _append_task(self, task: Dict[str, Any]):
        with self._lock:
            tasks = self._load_tasks()
            tasks.append(task)
            self._save_tasks(tasks)

    def _update_task(self, task_id: str, updates: Dict[str, Any]):
        with self._lock:
            tasks = self._load_tasks()
            for task in tasks:
                if task.get("id") == task_id:
                    task.update(updates)
                    break
            self._save_tasks(tasks)

    def _log_to_daily(self, message: str):
        # Logging to a text file is append-only, less critical to lock but good practice.
        # However, Python's file append is atomic on POSIX for small writes.
        # We'll lock to be consistent.
        with self._lock:
            today = datetime.date.today().isoformat()
            log_path = os.path.join(self.parking_dir, f"thought_parking_{today}.txt")
            with open(log_path, "a", encoding="utf-8") as f:
                f.write(message + "\n")

    def _format_result_for_log(self, result: Optional[str]) -> List[str]:
        """Normalize a potentially multi-line result into concise log lines."""
        if result is None:
            return ["(æ— è¿”å›žç»“æžœ)"]
        lines: List[str] = []
        for raw in str(result).splitlines():
            line = raw.strip()
            if not line:
                continue
            lines.append(line)
            if len(lines) >= 20:
                break
        return lines or ["(æ— è¿”å›žç»“æžœ)"]

    def _process_task_background(self, task_id: str):
        """Execute background work for search tasks without blocking user flow."""
        self._update_task(task_id, {"status": TaskStatus.PROCESSING.value})

        tasks = self._load_tasks()
        task = next((t for t in tasks if t.get("id") == task_id), None)
        if not task:
            return

        content = task.get("content", "")

        try:
            result = self._perform_search(content)
            self._update_task(
                task_id,
                {
                    "status": TaskStatus.COMPLETED.value,
                    "result": result,
                    "completed_at": datetime.datetime.now().strftime(
                        "%Y-%m-%d %H:%M:%S"
                    ),
                },
            )
            self._log_to_daily(
                f"[{datetime.datetime.now().strftime('%H:%M:%S')}] âœ… å®Œæˆ: {content[:30]}"
            )
            for line in self._format_result_for_log(result):
                self._log_to_daily(f"   â†’ {line}")
        except Exception as exc:  # pragma: no cover - defensive fallback
            self._update_task(
                task_id, {"status": TaskStatus.FAILED.value, "error": str(exc)}
            )
            self._log_to_daily(
                f"[{datetime.datetime.now().strftime('%H:%M:%S')}] âŒ å¤±è´¥: {content[:30]}"
            )
            self._log_to_daily(f"   â†’ é”™è¯¯: {exc}")

    def _internet_search(self, query: str) -> str:
        """Search DuckDuckGo and return a formatted summary."""
        query_text = (query or "").strip()
        if not query_text:
            return "æœªæä¾›æŸ¥è¯¢å†…å®¹ã€‚"

        try:
            with DDGS() as ddgs:
                results = list(ddgs.text(query_text, max_results=3))
        except Exception as exc:
            message = str(exc)
            lowered = message.lower()
            if "429" in message or "too many requests" in lowered:
                return "æœç´¢è¯·æ±‚è¿‡äºŽé¢‘ç¹ï¼Œè¯·ç¨åŽå†è¯•ã€‚"
            if "timeout" in lowered:
                return "æœç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨"
            return f"æœç´¢å¤±è´¥: {message}"

        if not results:
            return "æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œå»ºè®®æ¢ä¸ªå…³é”®è¯ã€‚"

        lines: List[str] = ["ðŸ” æœç´¢ç»“æžœï¼š", ""]
        for idx, item in enumerate(results, start=1):
            title = (item.get("title") or "æ— æ ‡é¢˜").strip()
            url = (
                item.get("href")
                or item.get("url")
                or item.get("link")
                or item.get("source")
                or ""
            )
            snippet = (
                item.get("body") or item.get("snippet") or item.get("description") or ""
            )
            snippet = " ".join(str(snippet).split())
            if len(snippet) > 100:
                snippet = snippet[:100].rstrip() + "..."

            lines.append(f"{idx}. {title}")
            if snippet:
                lines.append(f"   {snippet}")
            if url:
                lines.append(f"   æ¥æº: {url}")
            lines.append("")

        lines.append(f"ï¼ˆå…± {len(results)} æ¡ç»“æžœï¼Œå®Œæ•´å†…å®¹è§ current_parking.jsonï¼‰")
        return "\n".join(lines).rstrip()

    def _fetch_with_webfetch(self, url: str) -> str:
        """Fallback to WebFetch for direct URLs."""
        try:
            from connectonion import Agent, WebFetch
        except ImportError:
            return "[ç³»ç»Ÿé”™è¯¯] æ— æ³•å¯¼å…¥ ConnectOnion ç»„ä»¶ã€‚"

        system_instruction = (
            "ä½ ä½¿ç”¨ WebFetch æŠ“å–å¹¶æ€»ç»“ç½‘é¡µå†…å®¹ã€‚"
            "åªå¤„ç†å·²ç»æä¾›çš„ URLï¼Œä¸è¦å°è¯•æœç´¢æˆ–çŒœæµ‹å…¶ä»–é“¾æŽ¥ã€‚"
            "è¾“å‡ºç®€æ´æ‘˜è¦å’Œå…³é”®è¦ç‚¹ã€‚"
        )

        try:
            web_tool = WebFetch()
            searcher = Agent(
                name="parking_searcher",
                model="co/gemini-2.5-pro",
                tools=[web_tool],
                system_prompt=system_instruction,
                quiet=True,
            )
            prompt = (
                "è¯·æŠ“å–å¹¶æ€»ç»“ä»¥ä¸‹ç½‘é¡µçš„æ ¸å¿ƒä¿¡æ¯ï¼Œç»™å‡ºè¦ç‚¹å¼æ‘˜è¦ï¼š\n"
                f"{url}\n"
                "ä¸è¦è¿›è¡Œé¢å¤–æœç´¢ã€‚"
            )
            result = searcher.input(prompt)
            return str(result)
        except Exception as exc:
            return f"[å¤„ç†å¤±è´¥] ç½‘é¡µæŠ“å–å‡ºé”™: {exc}"

    def _perform_search(self, query: str) -> str:
        """
        Search-first flow: keyword uses DuckDuckGo, URL keeps WebFetch summary.
        """
        query_text = (query or "").strip()
        if query_text.lower().startswith(("http://", "https://")):
            return self._fetch_with_webfetch(query_text)
        return self._internet_search(query_text)


class ParkingToolkit:
    """Agent-facing toolkit wrapper around ParkingService."""

    def __init__(self, service: Optional[ParkingService] = None):
        self.service = service or ParkingService()

    def park_thought(
        self, content: str, thought_type: str = TaskType.SEARCH.value
    ) -> str:
        """
        Stash a thought or query for background processing.
        thought_type: search | memo | todo
        """
        normalized_type = (thought_type or TaskType.SEARCH.value).lower()
        return self.service.dispatch_task(
            content=content,
            task_type=normalized_type,
            source="focus_mode",
            run_async=True,
        )

    def get_parking_summary(self) -> str:
        """Return processed results for the active focus session."""
        return self.service.get_session_summary()
